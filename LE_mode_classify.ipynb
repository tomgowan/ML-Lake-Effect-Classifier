{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model to Classify Lake-Effect Mode\n",
    "This code will use several years of human-labelled lake-effect mode data (reflectivity) over the Tug Hill to train a deep learning model to classify lake-effect mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import scipy.ndimage\n",
    "import matplotlib.patches as patches\n",
    "sys.modules['__main__'].__file__ = 'ipython'\n",
    "from netCDF4 import Dataset\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "c = LocalCluster(n_workers=40, threads_per_worker=1)\n",
    "client = Client(c)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in netcdf radar files and csv files with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ds_rad = xr.open_mfdataset('/glade/scratch/tomg/tug_radar_netcdf_daily/*', parallel = True,\\\n",
    "                                 coords=\"minimal\", data_vars=\"minimal\", compat=\"minimal\", chunks={'time': 1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%time ds_rad = xr.open_mfdataset('/glade/scratch/tomg/tug_radar_netcdf_monthly/*', parallel = True, concat_dim=\"time\",\\\n",
    "#                  data_vars='minimal', coords='minimal', compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert time into YYYYMMDDHHMM\n",
    "year = ds_rad['time.year'].values\n",
    "month = ds_rad['time.month'].values\n",
    "day = ds_rad['time.day'].values\n",
    "hour = ds_rad['time.hour'].values\n",
    "minute = ds_rad['time.minute'].values\n",
    "\n",
    "rad_time = np.zeros(len(year))\n",
    "for i in range(len(year)):\n",
    "    rad_time[i] = np.int(\"{:04d}{:02d}{:02d}{:02d}{:02d}\".format(year[i], month[i], day[i], hour[i], minute[i]))\n",
    "rad_time = rad_time.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CSV files with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Labels #################################\n",
    "# SHORE = 0\n",
    "# MISC = 1\n",
    "# OROG = 2\n",
    "# HYBRID = 3\n",
    "# MCV = 4\n",
    "# LLAP1 = 5\n",
    "# BROAD = 6\n",
    "\n",
    "#Read in Labels\n",
    "labels_raw = pd.read_excel('/glade/scratch/tomg/tug_mode_labels/Morphology_Type_ScatEdit.xlsx')\n",
    "labels = np.squeeze(np.array(labels_raw), axis = 1)\n",
    "\n",
    "labels_num = np.zeros(len(labels))-1\n",
    "for i in range(len(labels)):\n",
    "\n",
    "    if labels[i] == 'SHORE':\n",
    "        labels_num[i] = 0\n",
    "    elif labels[i] == 'MISC':\n",
    "        labels_num[i] = 1\n",
    "    elif labels[i] == 'OROG':\n",
    "        labels_num[i] = 2\n",
    "    elif labels[i] == 'HYBRID':\n",
    "        labels_num[i] = 3\n",
    "    elif labels[i] == 'MCV':\n",
    "        labels_num[i] = 4\n",
    "    elif labels[i] == 'LLAP1':\n",
    "        labels_num[i] = 5\n",
    "    elif labels[i] == 'BROAD':\n",
    "        labels_num[i] = 6\n",
    "    \n",
    "    \n",
    "####################### Label Times ###############################\n",
    "#Read in start and end times\n",
    "labels_start_raw = pd.read_excel('/glade/scratch/tomg/tug_mode_labels/Morphology_Start_ScatEdit.xlsx')\n",
    "labels_end_raw = pd.read_excel('/glade/scratch/tomg/tug_mode_labels/Morphology_End_ScatEdit.xlsx')\n",
    "\n",
    "#Clean up times into YYYYMMDDHHMM\n",
    "labels_start = np.squeeze(np.array(labels_start_raw), axis = 1)\n",
    "labels_end = np.squeeze(np.array(labels_end_raw), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Times with Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array to save mode\n",
    "mode = np.zeros(len(rad_time))-1\n",
    "\n",
    "#Loop through all times with radar scans\n",
    "for i in range(len(rad_time)):\n",
    "    \n",
    "    #Loop through all labelled periods to make sure the period has only one mode\n",
    "    count = 0 \n",
    "    for j in range(len(labels)):\n",
    "        if labels_start[j] < rad_time[i] < labels_end[j]:\n",
    "            count = count + 1\n",
    "        \n",
    "    #If period has one mode find it and save it\n",
    "    if count == 1:\n",
    "        for j in range(len(labels)): \n",
    "            if labels_start[j] < rad_time[i] < labels_end[j]:\n",
    "                mode[i] = np.array(labels_num[j])\n",
    "\n",
    "                \n",
    "#Determine which indicies to keep (keep all rare modes and remove commong modes [BROAD and LLAP])\n",
    "#Get indicies for all rare modes\n",
    "ind_rare = np.squeeze(np.where((mode == 0)|(mode == 1)|(mode == 2)|(mode == 3)|(mode == 4)), axis = 0)\n",
    "#ind_rare = np.squeeze(np.where((mode == 0)|(mode == 1)|(mode == 2)), axis = 0)\n",
    "\n",
    "#Get 1000 random indicies for LLAP1\n",
    "ind_llap = np.squeeze(np.where(mode == 5), axis = 0)\n",
    "rand_llap = np.random.randint(0, len(ind_llap), 1500)\n",
    "\n",
    "#Get 1000 random indicies for BROAD                    \n",
    "ind_broad = np.squeeze(np.where(mode == 6), axis = 0)\n",
    "rand_broad = np.random.randint(0, len(ind_broad), 1500)\n",
    "\n",
    "#Combine indicies                      \n",
    "ind = np.concatenate((ind_rare, ind_llap[rand_llap], ind_broad[rand_broad]), axis = 0)\n",
    "\n",
    "#Load in data with proper indicies\n",
    "mode_clean = np.array(mode[ind]) #Only use mode data with those indicies\n",
    "%time ref_clean = np.array(ds_rad.bref[ind,:,:]) #Load in ref data for those indicies\n",
    "ref_clean[np.isnan(ref_clean)] = 0 #Remove nans (NN cant ingest them) \n",
    "\n",
    "#Look at how many examples for each mode\n",
    "print(np.count_nonzero(mode_clean == 0))\n",
    "print(np.count_nonzero(mode_clean == 1))\n",
    "print(np.count_nonzero(mode_clean == 2))\n",
    "print(np.count_nonzero(mode_clean == 3))\n",
    "print(np.count_nonzero(mode_clean == 4))\n",
    "print(np.count_nonzero(mode_clean == 5))\n",
    "print(np.count_nonzero(mode_clean == 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.keras.backend.clear_session()\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "keras.backend.clear_session()\n",
    "\n",
    "\n",
    "#Separate into train and test data\n",
    "train_per = 0.80 #Portion of data for training\n",
    "num_train = np.int(len(mode_clean)*train_per)\n",
    "\n",
    "indices = np.random.permutation(mode_clean.shape[0])\n",
    "train_ind, test_ind = indices[:num_train], indices[num_train:]\n",
    "x_train, x_test = ref_clean[train_ind,:,:], ref_clean[test_ind,:,:]\n",
    "y_train, y_test = mode_clean[train_ind], mode_clean[test_ind]\n",
    "\n",
    "\n",
    "#Normalize\n",
    "x_train = keras.utils.normalize(x_train)\n",
    "x_test = keras.utils.normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = len(ref_clean[0,:,0]), len(ref_clean[0,0,:])\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n",
    "input_shape = (img_rows, img_cols,1)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train2 = to_categorical(y_train)\n",
    "y_test2 = to_categorical(y_test)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(300, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(300, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(7, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss ='sparse_categorical_crossentropy',\n",
    "             metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size = 10, \n",
    "          epochs = 20)\n",
    "\n",
    "##########################################\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape = input_shape))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "# model.add(tf.keras.layers.Dense(7, activation='softmax'))\n",
    "# # compile model\n",
    "# opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(x_train, y_train2, \n",
    "#           batch_size = 10, \n",
    "#           epochs = 10)\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "#                  activation ='relu', input_shape = input_shape))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "#                  activation ='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation = \"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation = \"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(7, activation = \"softmax\"))\n",
    "\n",
    "# # compile model\n",
    "# opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(x_train, y_train2, \n",
    "#           batch_size = 10, \n",
    "#           epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_test, y_test, batch_size=10, verbose=0)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = model.predict(x_test[:3])\n",
    "print('predictions shape:', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in np.arange(100):\n",
    "for x in np.arange(500):\n",
    "\n",
    "\n",
    "    predictions = model.predict(x_test[x:x+1,:,:])\n",
    "    #print(predictions)\n",
    "\n",
    "    num_predict = np.argmax(predictions)\n",
    "    #print(predictions)\n",
    "    print(np.max(predictions)*100)\n",
    "    ind = test_ind[x]\n",
    "\n",
    "    num_actual = np.int(mode_clean[ind])\n",
    "\n",
    "    mode_labs = ['SHORE', 'MISC', 'OROG', 'HYBRID',  'MCV', 'LLAP1', 'BROAD',]\n",
    "\n",
    "    print(x)\n",
    "    print('predicted mode:{0}'.format(mode_labs[num_predict]))\n",
    "    print('actual mode:{0}\\n'.format(mode_labs[num_actual]))\n",
    "    \n",
    "    #plt.contourf(ref_clean[ind], levels = np.arange(0.5,30,2),cmap = cm.jet)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io.srtm import srtm_composite\n",
    "import cartopy.feature as cfeature\n",
    "sys.path.append('/glade/u/home/tomg/modules')\n",
    "import nclcmaps\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "\n",
    "#Get lat and lons\n",
    "lat = ds_rad.lat.values\n",
    "lon = ds_rad.lon.values\n",
    "\n",
    "for i in range(6,7):\n",
    "\n",
    "\n",
    "    fig = plt.figure(num=None, figsize=(11,6), facecolor='w', edgecolor='k')\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.72, top=0.98, wspace=0.2, hspace=0.1)\n",
    "\n",
    "\n",
    "    #Levels for theta\n",
    "    tlmin = 5\n",
    "    tlmax = 40.001\n",
    "    tlevels = np.arange(tlmin,tlmax, 0.5)\n",
    "    tlevels_ticks = np.arange(tlmin,tlmax,5)\n",
    "    tlevels_ticks_labels = np.arange(tlmin,tlmax, 5).astype(int)\n",
    "\n",
    "\n",
    "    #Colormap\n",
    "    colors1 = np.array(nclcmaps.colors['prcp_1'])\n",
    "    colors_int = colors1.astype(int)\n",
    "    colors = list(colors_int)\n",
    "    cmap_1 = nclcmaps.make_cmap(colors, bit=True)\n",
    "\n",
    "    #Bounds\n",
    "    xtick_freq = 120\n",
    "    ytick_freq = 120\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #########################################################################\n",
    "    ####################### 1. Tug Hill Domain ##############################\n",
    "    #########################################################################\n",
    "\n",
    "    ax = plt.subplot(111,aspect = 'equal',projection=ccrs.Mercator(globe = None, central_longitude=180))\n",
    "\n",
    "\n",
    "    land = cartopy.feature.LAND.with_scale('10m')\n",
    "    lakes = cartopy.feature.LAKES.with_scale('10m')\n",
    "    coast = cartopy.feature.COASTLINE.with_scale('10m')\n",
    "    bord = cartopy.feature.BORDERS.with_scale('10m')\n",
    "    \n",
    "    ax.add_feature(land)\n",
    "    ax.add_feature(lakes, edgecolor = 'k', zorder = 5)\n",
    "    ax.add_feature(coast, zorder = 5)\n",
    "    ax.add_feature(bord, zorder = 5)\n",
    "\n",
    "    lat2 = np.rot90(np.tile(lat,(len(lon),1)),3)\n",
    "    lon2 = np.rot90(np.tile(lon,(len(lat),1)),0)-180\n",
    "    proj = ccrs.Mercator()\n",
    "    out_points = proj.transform_points(ccrs.PlateCarree(), \n",
    "                            lon2, lat2)\n",
    "    \n",
    "    \n",
    "    #Make prediction\n",
    "    predictions = model.predict(x_test[i:i+1,:,:])\n",
    "    #Index of prediction\n",
    "    num_predict = np.argmax(predictions)\n",
    "    #Index of actual\n",
    "    ind = test_ind[i]\n",
    "    num_actual = np.int(mode_clean[ind])\n",
    "\n",
    "\n",
    "    \n",
    "    #Plot\n",
    "    bref_plot = plt.contourf(out_points[:,:, 0], out_points[:,:, 1], ref_clean[ind], tlevels, alpha = 1,\n",
    "        extend = 'max', cmap = cmap_1, zorder = 6)\n",
    "\n",
    "\n",
    "    ax.set_extent([-78, -74.5, 43, 44.5], crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "    #Plot Characteristics\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    plt.ylabel('Latitude', fontsize = 12)\n",
    "    plt.xlabel('Longitude', fontsize = 12)\n",
    "\n",
    "\n",
    "    gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "    \n",
    "    gl.xlocator = mticker.FixedLocator(np.arange(-180,180,0.6))\n",
    "    gl.ylocator = mticker.FixedLocator(np.arange(-180,180,0.3))\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.ylabel_style = {'size': 13}\n",
    "    gl.xlabel_style = {'size': 13}\n",
    "    \n",
    "    #Classificaiton    #Print mode corresponding to index\n",
    "    mode_labs = ['SHORE', 'MISC', 'OROG', 'HYBRID',  'MCV', 'LLAP', 'BROAD',]\n",
    "    props = dict(boxstyle='square', facecolor='white', alpha=0.8, ec=\"gray\")\n",
    "    ax.text(0.03, 0.76, 'Deep Neural Net mode: {}\\nConfidence: {:.2f}%\\nActual mode: {}'.format(mode_labs[num_predict],np.max(predictions)*100,mode_labs[num_actual]),\\\n",
    "        transform=ax.transAxes,bbox = props, fontsize = 17, zorder = 20)\n",
    "\n",
    "    #Colorbar\n",
    "    cbaxes = fig.add_axes([0.83, 0.323, 0.04, 0.5])\n",
    "    cbar = plt.colorbar(bref_plot, orientation='vertical', cax = cbaxes, ticks = tlevels_ticks)\n",
    "    cbar.ax.set_yticklabels(tlevels_ticks_labels)\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    plt.text(0.63,-0.14, 'Reflectivity\\n(dBZ)', fontsize = 15, ha='center', va='center')\n",
    "\n",
    "    #Plot and Save Figure\n",
    "    plt.savefig(\"tug_ml_classify_examples_{}.png\".format(i), dpi = 300)\n",
    "    plt.show(fig)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
